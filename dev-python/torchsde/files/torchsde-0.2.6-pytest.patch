From eb3a00e31cbd56176270066ed2f62c394cf6acb7 Mon Sep 17 00:00:00 2001
From: Benson Muite <benson_muite@emailplus.org>
Date: Sun, 29 Dec 2024 21:00:20 +0300
Subject: [PATCH] Enable compatibility with pytest 8.3.4

---
 tests/test_brownian_interval.py | 14 +++++++-------
 tests/test_brownian_path.py     |  6 +++---
 tests/test_brownian_tree.py     |  6 +++---
 3 files changed, 13 insertions(+), 13 deletions(-)

diff --git a/tests/test_brownian_interval.py b/tests/test_brownian_interval.py
index cb870fd7..2ebe3b15 100644
--- a/tests/test_brownian_interval.py
+++ b/tests/test_brownian_interval.py
@@ -70,7 +70,7 @@ def _levy_returns():
 @pytest.mark.parametrize("levy_area_approximation, return_U, return_A", _levy_returns())
 def test_shape(device, levy_area_approximation, return_U, return_A):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     for shape, A_shape in (((SMALL_BATCH_SIZE, D), (SMALL_BATCH_SIZE, D, D)),
                            ((SMALL_BATCH_SIZE,), (SMALL_BATCH_SIZE,)),
@@ -111,7 +111,7 @@ def test_shape(device, levy_area_approximation, return_U, return_A):
 @pytest.mark.parametrize("levy_area_approximation, return_U, return_A", _levy_returns())
 def test_determinism_simple(device, levy_area_approximation, return_U, return_A):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     ta, tb, bm = _setup(device, levy_area_approximation, (SMALL_BATCH_SIZE, D))
     vals = [bm(ta, tb, return_U=return_U, return_A=return_A) for _ in range(REPS)]
@@ -136,7 +136,7 @@ def test_determinism_large(device, levy_area_approximation, return_U, return_A):
     points, and compare.
     """
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     ta, tb, bm = _setup(device, levy_area_approximation, (SMALL_BATCH_SIZE, D))
     cache = {}
@@ -165,7 +165,7 @@ def test_determinism_large(device, levy_area_approximation, return_U, return_A):
 @pytest.mark.parametrize("levy_area_approximation", ['none', 'space-time', 'davie', 'foster'])
 def test_normality_simple(device, levy_area_approximation):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t0, t1 = 0.0, 1.0
     for _ in range(REPS):
@@ -199,7 +199,7 @@ def test_normality_simple(device, levy_area_approximation):
 @pytest.mark.parametrize("levy_area_approximation", ['none', 'space-time', 'davie', 'foster'])
 def test_normality_conditional(device, levy_area_approximation):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t0, t1 = 0.0, 1.0
     for _ in range(REPS):
@@ -262,7 +262,7 @@ def test_normality_conditional(device, levy_area_approximation):
 @pytest.mark.parametrize("levy_area_approximation", ['none', 'space-time', 'davie', 'foster'])
 def test_consistency(device, levy_area_approximation):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t0, t1 = 0.0, 1.0
     for _ in range(REPS):
@@ -293,7 +293,7 @@ def test_consistency(device, levy_area_approximation):
 @pytest.mark.parametrize("levy_area_approximation, return_U, return_A", _levy_returns())
 def test_entropy_determinism(random_order, device, levy_area_approximation, return_U, return_A):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t0, t1 = 0.0, 1.0
     entropy = 56789
diff --git a/tests/test_brownian_path.py b/tests/test_brownian_path.py
index 10cad160..83cb9704 100644
--- a/tests/test_brownian_path.py
+++ b/tests/test_brownian_path.py
@@ -51,7 +51,7 @@ def _setup(device):
 @pytest.mark.parametrize("device", devices)
 def test_basic(device):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t, bm = _setup(device)
     sample = bm(t)
@@ -61,7 +61,7 @@ def test_basic(device):
 @pytest.mark.parametrize("device", devices)
 def test_determinism(device):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t, bm = _setup(device)
     vals = [bm(t) for _ in range(REPS)]
@@ -72,7 +72,7 @@ def test_determinism(device):
 @pytest.mark.parametrize("device", devices)
 def test_normality(device):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t0_, t1_ = 0.0, 1.0
     eps = 1e-2
diff --git a/tests/test_brownian_tree.py b/tests/test_brownian_tree.py
index d3a84ff3..4e899ec1 100644
--- a/tests/test_brownian_tree.py
+++ b/tests/test_brownian_tree.py
@@ -58,7 +58,7 @@ def _dict_to_sorted_list(*dicts):
 @pytest.mark.parametrize("device", devices)
 def test_basic(device):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t, bm = _setup(device, SMALL_BATCH_SIZE)
     sample = bm(t)
@@ -68,7 +68,7 @@ def test_basic(device):
 @pytest.mark.parametrize("device", devices)
 def test_determinism(device):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t, bm = _setup(device, SMALL_BATCH_SIZE)
     vals = [bm(t) for _ in range(REPS)]
@@ -79,7 +79,7 @@ def test_determinism(device):
 @pytest.mark.parametrize("device", devices)
 def test_normality(device):
     if device == gpu and not torch.cuda.is_available():
-        pytest.skip(msg="CUDA not available.")
+        pytest.skip(reason="CUDA not available.")
 
     t0_, t1_ = 0.0, 1.0
     t0, t1 = torch.tensor([t0_, t1_], device=device)
